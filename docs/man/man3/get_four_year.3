.TH "get_four_year" 3 "Version 3" "ASP Schedule Optimizer" \" -*- nroff -*-
.ad l
.nh
.SH NAME
get_four_year \- This module contains all of the functionality that is needed to process the four year plan that is given with some url\&.  

.SH SYNOPSIS
.br
.PP
.SS "Functions"

.in +1c
.ti -1c
.RI "\fBget_all_tables\fP (bs soup)"
.br
.RI "Finds all of the tables in the page gathered with BS4\&. "
.ti -1c
.RI "list \fBget_table_rows\fP (table)"
.br
.RI "Given a table, returns all its rows\&. "
.ti -1c
.RI "\fBprocess_url\fP (str url)"
.br
.RI "Take a url and find all of the tables contained in the page and return a ResultSet\&. "
.ti -1c
.RI "\fBread_four_year\fP (url, output_file)"
.br
.RI "From a url that contains a four year plan process it and produce a JSON file in a structure that we can utilize to then convert into a clingo file\&. "
.in -1c
.SS "Variables"

.in +1c
.ti -1c
.RI "\fBcurrent_directory\fP = os\&.path\&.dirname(os\&.path\&.realpath(__file__))"
.br
.ti -1c
.RI "\fBpath\fP = current_directory\&.split(os\&.sep)"
.br
.ti -1c
.RI "\fBroot_index\fP = path\&.index('Capstone\-Team14')"
.br
.ti -1c
.RI "\fBroot_dir\fP = os\&.sep\&.join(path[:root_index+1])"
.br
.ti -1c
.RI "\fBdata_dir\fP = os\&.path\&.join(root_dir, 'data_files', 'four_year_plan')"
.br
.ti -1c
.RI "\fBfilename\fP = os\&.path\&.join(data_dir,'fourYearPlan\&.json')"
.br
.ti -1c
.RI "str \fBurl\fP = 'https://catalog\&.unomaha\&.edu/undergraduate/college\-information\-science\-technology/computer\-science/computer\-science\-bs/#fouryearplantext'"
.br
.in -1c
.SH "Detailed Description"
.PP 
This module contains all of the functionality that is needed to process the four year plan that is given with some url\&. 

For proof of concept running this package as a script utilizes the Computer Science four year plan\&. 
.SH "Function Documentation"
.PP 
.SS "get_four_year\&.get_all_tables (bs soup)"

.PP
Finds all of the tables in the page gathered with BS4\&. 
.PP
\fBParameters\fP
.RS 4
\fIsoup\fP The BeautifulSoup4 representation of the web page 
.RE
.PP
\fBReturns\fP
.RS 4
A set containing all of the instances of \fR<table></table>\fP along with all of its contents 
.RE
.PP

.PP
Definition at line \fB18\fP of file \fBget_four_year\&.py\fP\&.
.nf
18 def get_all_tables(soup: bs):
19     return soup\&.find_all("table")
20 
.PP
.fi

.SS " list get_four_year\&.get_table_rows ( table)"

.PP
Given a table, returns all its rows\&. 
.PP
\fBParameters\fP
.RS 4
\fItable\fP A table from web page grabbed using BS4 soup object 
.RE
.PP
\fBReturns\fP
.RS 4
A 2d list that represents all of the rows from the table 
.RE
.PP

.PP
Definition at line \fB25\fP of file \fBget_four_year\&.py\fP\&.
.nf
25 def get_table_rows(table) \-> list:
26     rows = []
27     for tr in table\&.find_all("tr")[0:]:
28         cells = []
29         # grab all td tags in this table row
30         tds = tr\&.find_all("td")
31         if len(tds) == 0:
32             # if no td tags, search for th tags
33             # can be found especially in wikipedia tables below the table
34             ths = tr\&.find_all("th")
35             for th in ths:
36                 cells\&.append(th\&.text\&.strip())
37         else:
38             # use regular td tags
39             for td in tds:
40                 cells\&.append(td\&.text\&.strip())
41         rows\&.append(cells)
42     return rows
43 
44     
.PP
.fi

.SS "get_four_year\&.process_url (str url)"

.PP
Take a url and find all of the tables contained in the page and return a ResultSet\&. 
.PP
\fBParameters\fP
.RS 4
\fIurl\fP URL of the page to be searched\&. 
.RE
.PP
\fBReturns\fP
.RS 4
List containing all of the tables in the page\&. Each of table is a 2d array (list) 
.RE
.PP

.PP
Definition at line \fB50\fP of file \fBget_four_year\&.py\fP\&.
.nf
50 def process_url(url: str):
51     
52     tables_list = []
53     # print(nfl_url)
54     data = requests\&.get(url)
55     if data\&.status_code != 200:
56         print(data\&.status_code)
57         print('Request failed at:',url)
58         return tables_list
59     response = bs(data\&.content, "html\&.parser")
60     
61     # extract all the tables from the web page
62     tables_list = get_all_tables(response)
63     print(f"[+] Found a total of {len(tables_list)} tables\&.")
64     if len(tables_list) == 0:
65         print(f'No Data: {url}')
66     
67     tables=[]
68     for table in tables_list:
69         tables\&.append(get_table_rows(table))
70     return tables
71     pass
72 
.PP
.fi

.SS "get_four_year\&.read_four_year ( url,  output_file)"

.PP
From a url that contains a four year plan process it and produce a JSON file in a structure that we can utilize to then convert into a clingo file\&. For the page in the computer science four year plan, create a JSON file with the class content organized by year and semester\&. This data is then used to discover conflicts that are higher priority\&.

.PP
@params url A string containing the url for the page with the four year plan @params output_file A string that contains the file path and filename that the JSON will be written to\&.

.PP
\fINOTE\fP to maintain the script's OS agnostic nature, it is suggested to utilize os\&.path\&.join() to join strings or os\&.sep\&.join() to join elements of a list 
.PP
Definition at line \fB87\fP of file \fBget_four_year\&.py\fP\&.
.nf
87 def read_four_year(url, output_file):
88     
89     tables_list = process_url(url)
90     json_data = []
91     for table in tables_list[1:]:
92         structured_rows = {
93             'First Year': {
94                 'FALL': [],
95                 'SPRING': []
96             },
97             'Second Year': {
98                 'FALL': [],
99                 'SPRING': []
100             },
101             'Third Year': {
102                 'FALL': [],
103                 'SPRING': []
104             },
105             'Fourth Year': {
106                 'FALL': [],
107                 'SPRING': []
108             }
109         }
110         classes_in_semeseter = []
111         year = ''
112         semester = ''
113         for row in table:
114             # print(row)
115             # print(len(row))
116             if row[0] in structured_rows\&.keys():
117                 if semester != '':
118                     structured_rows[year][semester] = classes_in_semeseter
119                     classes_in_semeseter = []
120                     semester = ''
121                 year = row[0]
122                     
123             elif row[0]\&.upper() in structured_rows[year]\&.keys():
124                 if semester != '':
125                     structured_rows[year][semester] = classes_in_semeseter
126                     classes_in_semeseter = []
127                 semester = row[0]\&.upper()
128             else:
129                 if row[0] != '' and len(row) == 3:
130                     row[0] = row[0]\&.replace(u'\\xa0', ' ')
131                     row[0] = row[0]\&.split('or ')
132                     row[1] = row[1]\&.split('or ')
133                     renamed_courses = []
134                     for course in row[0]:
135                         renamed_courses\&.append(course\&.lower()\&.replace(' ', ''))
136                         
137                     row[0] = renamed_courses
138                     classes_in_semeseter\&.append(row)
139         structured_rows[year][semester] = classes_in_semeseter
140         # pprint(structured_rows)
141         json_data\&.append(structured_rows)
142     print("Finished Gathering Data")
143     
144     with open(output_file, 'w') as f:
145         json\&.dump(json_data,f, indent=4)
146     
.PP
.fi

.SH "Variable Documentation"
.PP 
.SS "get_four_year\&.current_directory = os\&.path\&.dirname(os\&.path\&.realpath(__file__))"

.PP
Definition at line \fB149\fP of file \fBget_four_year\&.py\fP\&.
.SS "get_four_year\&.data_dir = os\&.path\&.join(root_dir, 'data_files', 'four_year_plan')"

.PP
Definition at line \fB158\fP of file \fBget_four_year\&.py\fP\&.
.SS "get_four_year\&.filename = os\&.path\&.join(data_dir,'fourYearPlan\&.json')"

.PP
Definition at line \fB164\fP of file \fBget_four_year\&.py\fP\&.
.SS "get_four_year\&.path = current_directory\&.split(os\&.sep)"

.PP
Definition at line \fB154\fP of file \fBget_four_year\&.py\fP\&.
.SS "get_four_year\&.root_dir = os\&.sep\&.join(path[:root_index+1])"

.PP
Definition at line \fB157\fP of file \fBget_four_year\&.py\fP\&.
.SS "get_four_year\&.root_index = path\&.index('Capstone\-Team14')"

.PP
Definition at line \fB156\fP of file \fBget_four_year\&.py\fP\&.
.SS "str get_four_year\&.url = 'https://catalog\&.unomaha\&.edu/undergraduate/college\-information\-science\-technology/computer\-science/computer\-science\-bs/#fouryearplantext'"

.PP
Definition at line \fB165\fP of file \fBget_four_year\&.py\fP\&.
.SH "Author"
.PP 
Generated automatically by Doxygen for ASP Schedule Optimizer from the source code\&.
